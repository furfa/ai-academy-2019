{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Parse_series_base.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"vk4WBUarTx5g","colab_type":"code","outputId":"c327c709-4f3c-45f7-ad98-4d4a996b082d","executionInfo":{"status":"ok","timestamp":1555756476702,"user_tz":-180,"elapsed":1240,"user":{"displayName":"Александр Мячин","photoUrl":"https://lh3.googleusercontent.com/-0NFj7_tbRH0/AAAAAAAAAAI/AAAAAAAAB8s/Hhy2w0b-iKw/s64/photo.jpg","userId":"13004423397486691111"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive') # force_remount=True для переподключения"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"P7Gp7ri7T8iv","colab_type":"code","outputId":"0a11465b-f7a2-4d76-f736-339fe6619229","executionInfo":{"status":"ok","timestamp":1555759299677,"user_tz":-180,"elapsed":6723,"user":{"displayName":"Александр Мячин","photoUrl":"https://lh3.googleusercontent.com/-0NFj7_tbRH0/AAAAAAAAAAI/AAAAAAAAB8s/Hhy2w0b-iKw/s64/photo.jpg","userId":"13004423397486691111"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","import scipy\n","import sys\n","sys.path.append(\"..\")\n","import os\n","pd.set_option(\"max_columns\", 10000)\n","\n","%pylab inline\n","import seaborn as sns\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import json\n","from IPython import display\n","\n","from tqdm import tqdm, tqdm_notebook, tqdm_pandas\n","tqdm.pandas()\n","\n","import copy\n","\n","from datetime import datetime\n","\n","def submit(pred, base_name=\"\", pred_path=\"/home/furfa/work/ai-academy2019/predictions\"):\n","    date = str(datetime.now())\n","    name = f\"{base_name}[{date}].csv\"\n","    path = os.path.join(pred_path, name)\n","    pred.to_csv(path, index = None) # 40 баллов\n","    print(\"File saved in :\",path)\n","\n","from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n","\n","import json\n","\n","import featuretools as ft\n","\n","from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n","import plotly.graph_objs as go\n","\n","init_notebook_mode(connected=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Populating the interactive namespace from numpy and matplotlib\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/vnd.plotly.v1+html":"<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>","text/html":["<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"2WsZQLbkT_B9","colab_type":"code","outputId":"09c48be5-86c5-45de-e681-239ae35905af","executionInfo":{"status":"ok","timestamp":1555759311205,"user_tz":-180,"elapsed":5426,"user":{"displayName":"Александр Мячин","photoUrl":"https://lh3.googleusercontent.com/-0NFj7_tbRH0/AAAAAAAAAAI/AAAAAAAAB8s/Hhy2w0b-iKw/s64/photo.jpg","userId":"13004423397486691111"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["data  drive  predictions  sample_data\n"],"name":"stdout"}]},{"metadata":{"id":"ZJlyD2J7UCu5","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","def encode_columns(df, columns):\n","    for col in columns:\n","        le = LabelEncoder()\n","        df[col] = le.fit_transform(df[col].values)\n","\n","unique_roles = set()\n","def onehot_lists(series_lists):\n","\n","    def str_to_list(s):\n","        global unique_roles\n","        s = s[1:-1].split(\"', '\")\n","        s[0] = s[0][1:]\n","        s[-1] = s[-1][:-1]\n","        s = set(s)\n","        unique_roles = unique_roles | s\n","        return s\n","\n","    series_lists = series_lists.apply(str_to_list)\n","\n","    new_data = {role:list() for role in unique_roles}\n","\n","    for role in unique_roles:\n","        for l in series_lists:\n","            new_data[role].append( role in l )\n","\n","    new_data = pd.DataFrame(new_data)\n","\n","    return new_data\n","\n","def make_diff_shifts(row, n=1):\n","    \"\"\"\n","    row - np-array\n","    \"\"\"\n","    if n == 0:\n","        return row\n","\n","    return row[n:]- row[:-n]\n","\n","def linreg_trend(Y):\n","    \"\"\"\n","    return a,b in solution to y = ax + b such that root mean square distance between trend line and original points is minimized\n","    \"\"\"\n","    X = range(len(Y))\n","\n","    N = len(X)\n","    Sx = Sy = Sxx = Syy = Sxy = 0.0\n","    for x, y in zip(X, Y):\n","        Sx = Sx + x\n","        Sy = Sy + y\n","        Sxx = Sxx + x*x\n","        Syy = Syy + y*y\n","        Sxy = Sxy + x*y\n","    det = Sxx * N - Sx * Sx\n","\n","    trend_a = (Sxy * N - Sy * Sx)/det\n","    trend_b = (Sxx * Sy - Sx * Sxy)/det\n","    return trend_a\n","  \n","  \n","  \n","def generate_features(data, var_types, \n","                      trans_primitives=[\"multiply\",'divide', \"diff\"], N_FEATURES=1000, \n","                      index_col_name=\"id\"):\n","    data = data.copy()\n","    \n","    print(\"-\"*15)\n","\n","    start_columns = data.columns\n","    \n","    data = data.reset_index()\n","    data[index_col_name] = data[index_col_name].astype(np.int64)\n","    \n","    N_FEATURES += data.shape[1]\n","    \n","    es = ft.EntitySet(id='players')\n","    \n","    main_entity_id = 'train_players'\n","\n","    # Entities with a unique index\n","    es = es.entity_from_dataframe(\n","        entity_id=main_entity_id, \n","        dataframe=data, # dataframe object\n","        index=index_col_name, # unique index\n","        variable_types=var_types\n","    )\n","\n","    print(es)\n","    \n","    # DFS with specified primitives\n","    print(\"Start dfs\")\n","\n","    features, feature_names = ft.dfs(\n","        entityset=es, \n","        target_entity=main_entity_id,\n","        trans_primitives = trans_primitives,\n","        agg_primitives=[], \n","        max_depth=1, \n","        features_only=False,\n","        verbose=True,\n","        chunk_size=0.5,\n","        max_features=N_FEATURES, # comment it later, computational burden reduction\n","        n_jobs=-1,\n","    )\n","    return features.drop(start_columns, axis=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"peaG5wQXUJNu","colab_type":"code","colab":{}},"cell_type":"code","source":["input_dir = \"data\"\n","base_dir = \".\"\n","pred_dir = os.path.join(base_dir, \"predictions\")\n","processed_dir = os.path.join(input_dir, \"processed\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MaY8yz-bURAO","colab_type":"code","outputId":"9eca0f87-48ea-4e0d-e20e-5b87d2cd82f4","executionInfo":{"status":"ok","timestamp":1555758802477,"user_tz":-180,"elapsed":22995,"user":{"displayName":"Александр Мячин","photoUrl":"https://lh3.googleusercontent.com/-0NFj7_tbRH0/AAAAAAAAAAI/AAAAAAAAB8s/Hhy2w0b-iKw/s64/photo.jpg","userId":"13004423397486691111"}},"colab":{"base_uri":"https://localhost:8080/","height":73}},"cell_type":"code","source":["!ls {processed_dir}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["test_all_JSON.csv\t      train_all_JSON.csv\n","test_timeseries.csv\t      train_timeseries.csv\n","test_timeseries_no_zeros.csv  train_timeseries_no_zeros.csv\n"],"name":"stdout"}]},{"metadata":{"id":"CM7890-RnDv_","colab_type":"text"},"cell_type":"markdown","source":["# Series zeros"]},{"metadata":{"id":"M_HVPiFZUUlf","colab_type":"code","outputId":"5eaa418a-3009-4667-8d1f-93b0ebdbee37","executionInfo":{"status":"ok","timestamp":1555757597767,"user_tz":-180,"elapsed":914560,"user":{"displayName":"Александр Мячин","photoUrl":"https://lh3.googleusercontent.com/-0NFj7_tbRH0/AAAAAAAAAAI/AAAAAAAAB8s/Hhy2w0b-iKw/s64/photo.jpg","userId":"13004423397486691111"}},"colab":{"base_uri":"https://localhost:8080/","height":186}},"cell_type":"code","source":["def get_data(data_json_series, shifts, func_to_aggregate):\n","\n","\n","    data_series = {\n","        f\"{it}->{s}_{func.__name__}\":list() for func in func_to_aggregate\n","                            for it in (\"radiant\", \"dire\", \"time\", \"player\")\n","                            for s in shifts\n","\n","    }\n","    data_series[\"id\"] = list()\n","\n","    print(f\"making df with shape : {len(data_series.keys())}\")\n","\n","    for ind in tqdm(data_json_series.index):\n","        ser = json.loads(\n","            data_json_series[ind]\n","        )\n","\n","        data_series[\"id\"].append(ind)\n","\n","        sootv = {\n","            \"radiant\" : np.array(ser[\"radiant_gold\"]),\n","            \"dire\" : np.array(ser[\"dire_gold\"]),\n","            \"time\" : np.array(ser[\"time\"]),\n","            \"player\" : np.array(ser[\"player_gold\"]),\n","        }\n","\n","        for it in (\"radiant\", \"dire\", \"time\", \"player\"):\n","            for func in func_to_aggregate:\n","                for s in shifts:\n","                    data_series[f\"{it}->{s}_{func.__name__}\"].append(\n","                                                                func(\n","                                                                    make_diff_shifts(\n","                                                                        sootv[it],\n","                                                                        n=s\n","                                                                        )\n","                                                                    )\n","                                                                )\n","    return pd.DataFrame(data_series).set_index(\"id\")\n","\n","\n","\n","\n","func_to_aggregate = [\n","    np.max,\n","    scipy.stats.mode,\n","    np.mean,\n","    np.var,\n","    np.std,\n","    np.sum,\n","    scipy.stats.skew,\n","    linreg_trend,\n","]\n","\n","shifts = [\n","    0,1\n","]\n","\n","print(\"Reading\")\n","\n","train_ser = pd.read_csv( os.path.join(input_dir,\"processed\", 'train_all_JSON.csv'), index_col=0 )[\"series\"]\n","test_ser = pd.read_csv( os.path.join(input_dir, \"processed\", 'test_all_JSON.csv'), index_col=0 )[\"series\"]\n","\n","print(\"making train\")\n","new_data_train = get_data(train_ser, shifts, func_to_aggregate)\n","\n","print(\"making test\")\n","new_data_test = get_data(test_ser, shifts, func_to_aggregate)\n","\n","print(\"saving\")\n","\n","new_data_train.to_csv( os.path.join(input_dir,\"processed\", 'train_timeseries.csv') )\n","\n","new_data_test.to_csv( os.path.join(input_dir,\"processed\", 'test_timeseries.csv') )\n","\n","print(\"Ezzz\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Reading\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 11/40403 [00:00<06:37, 101.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["making train\n","making df with shape : 65\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 40403/40403 [06:16<00:00, 107.45it/s]\n","  0%|          | 11/15836 [00:00<02:28, 106.33it/s]"],"name":"stderr"},{"output_type":"stream","text":["making test\n","making df with shape : 65\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 15836/15836 [02:27<00:00, 107.13it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["saving\n","Ezzz\n"],"name":"stdout"}]},{"metadata":{"id":"MFcE36i0nJ8y","colab_type":"text"},"cell_type":"markdown","source":["# Series no zeros"]},{"metadata":{"id":"c6BepIsOUw6L","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_slice_no_zero(arr):\n","    for i in range(len(arr)):\n","        if arr[i] != 0:\n","            return i\n","    return 0\n","\n","def get_data_nz(data_json_series, shifts, func_to_aggregate):\n","\n","\n","    data_series = {\n","        f\"{it}->{s}_{func.__name__}\":list() for func in func_to_aggregate\n","                            for it in (\"radiant\", \"dire\", \"time\", \"player\")\n","                            for s in shifts\n","\n","    }\n","    data_series[\"id\"] = list()\n","\n","    print(f\"making df with shape : {len(data_series.keys())}\")\n","\n","    for ind in tqdm(data_json_series.index):\n","        ser = json.loads(\n","            data_json_series[ind]\n","        )\n","\n","        data_series[\"id\"].append(ind)\n","\n","        no_zero_slice = get_slice_no_zero(ser[\"time\"])\n","\n","        sootv = {\n","            \"radiant\" : np.array(ser[\"radiant_gold\"])[no_zero_slice:],\n","            \"dire\" : np.array(ser[\"dire_gold\"])[no_zero_slice:],\n","            \"time\" : np.array(ser[\"time\"])[no_zero_slice:],\n","            \"player\" : np.array(ser[\"player_gold\"])[no_zero_slice:],\n","        }\n","\n","        for it in (\"radiant\", \"dire\", \"time\", \"player\"):\n","            for func in func_to_aggregate:\n","                for s in shifts:\n","                    data_series[f\"{it}->{s}_{func.__name__}\"].append(\n","                                                                func(\n","                                                                    make_diff_shifts(\n","                                                                        sootv[it],\n","                                                                        n=s\n","                                                                        )\n","                                                                    )\n","                                                                )\n","    return pd.DataFrame(data_series).set_index(\"id\")\n","\n","\n","\n","func_to_aggregate = [\n","    np.max,\n","    np.mean,\n","    np.var,\n","    np.std,\n","    np.sum,\n","    linreg_trend,\n","]\n","\n","shifts = [\n","    0,1\n","]\n","\n","print(\"making train\")\n","new_data_train = get_data_nz(train_ser, shifts, func_to_aggregate)\n","\n","print(\"making test\")\n","new_data_test = get_data_nz(test_ser, shifts, func_to_aggregate)\n","\n","print(\"saving\")\n","\n","new_data_train.to_csv( os.path.join(input_dir,\"processed\", 'train_timeseries_no_zeros.csv') )\n","\n","new_data_test.to_csv( os.path.join(input_dir,\"processed\", 'test_timeseries_no_zeros.csv') )\n","\n","print(\"Ezzz\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YrjkfYkmXgIy","colab_type":"code","outputId":"3fb98b1a-867b-404f-9336-3dae123539de","executionInfo":{"status":"ok","timestamp":1555759676325,"user_tz":-180,"elapsed":352201,"user":{"displayName":"Александр Мячин","photoUrl":"https://lh3.googleusercontent.com/-0NFj7_tbRH0/AAAAAAAAAAI/AAAAAAAAB8s/Hhy2w0b-iKw/s64/photo.jpg","userId":"13004423397486691111"}},"colab":{"base_uri":"https://localhost:8080/","height":186}},"cell_type":"code","source":["def level_up_features(data_json_series, shifts, func_to_aggregate):\n","\n","    it = \"level\"\n","\n","    data_series = {\n","        f\"{it}->{s}_{func.__name__}\":list() for func in func_to_aggregate\n","                            for s in shifts\n","\n","    }\n","    data_series[\"id\"] = list()\n","\n","    print(f\"making df with shape : {len(data_series.keys())}\")\n","\n","    for ind in tqdm(data_json_series.index):\n","        ser = json.loads(\n","            data_json_series[ind]\n","        )\n","\n","        data_series[\"id\"].append(ind)\n","\n","        sootv = {\n","            \"level\" : np.array(ser),\n","        }\n","\n","        for func in func_to_aggregate:\n","            for s in shifts:\n","                try:\n","                    to_append =  func(\n","                                    make_diff_shifts(\n","                                        sootv[it],\n","                                        n=s\n","                                        )\n","                                    )\n","                except:\n","                    to_append = np.nan\n","\n","                data_series[f\"{it}->{s}_{func.__name__}\"].append(to_append)\n","    return pd.DataFrame(data_series).set_index(\"id\")\n","  \n","func_to_aggregate = [\n","      np.max,\n","      np.mean,\n","      np.std,\n","      np.sum,\n","      linreg_trend,\n","  ]\n","\n","shifts = [\n","    0,1\n","]\n","\n","print(\"Reading\")\n","\n","train_ser = pd.read_csv( os.path.join(input_dir,\"processed\", 'train_all_JSON.csv'), index_col=0 ).level_up_times\n","test_ser = pd.read_csv( os.path.join(input_dir, \"processed\", 'test_all_JSON.csv'), index_col=0 ).level_up_times\n","\n","print(\"making train\")\n","new_data_train = level_up_features(\n","        train_ser,\n","        shifts,\n","        func_to_aggregate\n",")\n","\n","print(\"making test\")\n","new_data_test = level_up_features(\n","        test_ser,\n","        shifts,\n","        func_to_aggregate\n",")\n","print(\"saving\")\n","\n","new_data_train.to_csv( os.path.join(input_dir,\"processed\", 'train_levelup.csv') )\n","\n","new_data_test.to_csv( os.path.join(input_dir,\"processed\", 'test_levelup.csv') )\n","\n","print(\"Ezzz\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Reading\n"],"name":"stdout"},{"output_type":"stream","text":["  1%|          | 394/40403 [00:00<00:10, 3933.85it/s]"],"name":"stderr"},{"output_type":"stream","text":["making train\n","making df with shape : 11\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 40403/40403 [00:10<00:00, 3838.82it/s]\n","  3%|▎         | 410/15836 [00:00<00:03, 4098.82it/s]"],"name":"stderr"},{"output_type":"stream","text":["making test\n","making df with shape : 11\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 15836/15836 [00:04<00:00, 3716.61it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["saving\n","Ezzz\n"],"name":"stdout"}]}]}